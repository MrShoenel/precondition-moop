---
title: "Pre-conditioning of multi-objective optimization problems"
author: "Sebastian Hönel"
date: "`r format(Sys.time(), '%B %d, %Y')`"
bibliography: ../inst/REFERENCES.bib
papersize: a4
urlcolor: blue
output:
  bookdown::pdf_document2:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 6
    df_print: kable
    keep_tex: yes
  md_document:
    toc: yes
    toc_depth: 6
    df_print: kable
    variant: gfm
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 6
    toc_float: yes
    df_print: kable
  word_document: default
header-includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{bm}
- \usepackage{mathtools}
- \usepackage{interval}
- \usepackage{xurl}
- \usepackage[nottoc]{tocbibind}
---

\intervalconfig{
    soft open fences
}

\newcommand*\mean[1]{\overline{#1}}
\newcommand{\abs}[1]{\left\lvert\,#1\,\right\rvert}
\newcommand{\norm}[1]{\left\lVert\,#1\,\right\rVert}
\newcommand{\infdiv}[2]{#1\;\|\;#2}
\newcommand\argmax[1]{\underset{#1}{arg\,max}}
\newcommand\argmin[1]{\underset{#1}{arg\,min}}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANG = "en_US.UTF-8")
Sys.setenv(LC_ALL = "en_US.UTF-8")
Sys.setenv(LC_CTYPE = "en_US.UTF-8")
```

```{r echo=FALSE}
source(file = "../helpers.R")
```


# Introduction

Multi-objective optimization problems (MOOPs) attempt to find solutions for a set of _non-aggregable_ objectives.
MOOPs are commonly formulated as in \eqref{eq:moop}:

\begin{align}
  \min_{\mathbf{x}\in\mathcal{X}}\,\left(f_1(\mathbf{x}),\dots,f_n(\mathbf{x})\right).\label{eq:moop}
\end{align}


Non-aggregable refers to conflicting objectives with differing range.
A solution $\mathbf{s}_1$ dominates another solution $\mathbf{s}_2$ iff $\norm{\mathbf{s}_1}<\norm{\mathbf{s}_2}$ and $\forall\,s\in\left(\mathbf{s}_1-\mathbf{s}_2\right)\,s\leq0$.
Furthermore, non-aggregable means that we cannot make any assumptions about the _trade-off_ between found solutions for single objectives, except for the stated dominance assumption.
The scalarizer in a MOOP is only means to an end, one has to inspect the resulting solution. The scalarizer in MOOPs does not technically transform a MOOP into a single-objective optimization problem (SOOP), because its value when a solution is found is meaningless.

However, we suggest using a form of __pre-conditioning__ for MOOPs that allows the scalarizer to quantify the trade-off between objectives and therefore relaxes the dominance assumption.
With the relaxation in place, the scalarizer's value becomes meaningful in that we can use it to compare solutions. If we were to do minimization, then a lower scalarized value would mean that a more optimal solution was found.


## Transforming objectives to scores

Commonly, objectives in MOOPs each have their own range (_magnitude_). To address this problem, objectives may be scaled into a dimensionless unit scale. This is done by defining $f'_i=f_i\times\left(z_i^{\mathrm{nad}}-z_i^{\mathrm{**}}\right)^{-1}$, where the _nadir_- and _utopian_ (**) vectors are, simply speaking, the worst and ideal objective vectors (refer to [@miettinen2008] for a more precise definition).
However, while this scaling results in objectives with a range of $\interval{0}{1}$ (which we call __scores__), these scores do __not__ have linear behavior. For example, a score of $0.9$ might not be better by $0.1$ than a score of $0.8$, but considerably better if high scores are hard to obtain for a specific objective.

Pre-conditioning of scores refers to transforming such raw scores into ones with linear behavior.
It can be achieved by approximating the empirical cumulative distribution ($\operatorname{ECDF}$) of an objective and then using this function to scale and _rectify_ an objective's values.
Furthermore, this approach does not require to scale by the range as established by nadir- and utopian vectors. While the nadir-vector is usually difficult to obtain, the utopian vector is the result of minimizing each objective separately in order to obtain the lowest possible loss.

In order to approximate the $\operatorname{ECDF}_i$, we can take $k$ uniformly chosen samples $\mathbf{h}$ \eqref{eq:hp-samples} from the hyperparameter space $\mathbf{H}$ \eqref{eq:hp-space} (where $k\lll m$) and compute losses for each $i$-th objective \eqref{eq:ith-obj}.
The observed losses are then used to approximate the marginal distribution of this objective and to create a uniform score with linear behavior \eqref{eq:ith-score}.

\begin{align}
  \mathbf{H}&\dots\text{matrix with dimensions }m\times n\label{eq:hp-space},
  \\[1ex]
  \mathbf{h}&\dots\text{matrix with dimensions }k\times n\text{ (}\mathbf{h}\sim\mathbb{U}_{\mathbf{H}}\text{),}\label{eq:hp-samples}
  \\[1ex]
  \mathcal{O}_i&:\mathbb{R}^{n}\mapsto\mathbb{R}^{+}\cup\{0\}\text{ (loss; lower is better)}\label{eq:ith-obj},
  \\[1ex]
  \mathcal{S}_i&=1-\operatorname{ECDF}\left(\mathcal{O}_i(\mathbf{h})\right)\label{eq:ith-score}.
\end{align}


If all of the objectives in a scalarizer were such pre-conditioned scores, then its resulting values can be used to compare solutions, which was not previously possible.



# Examples

Here, we show some examples where this may be useful.


## Optimizing volume and price of packages

In this problem, we want to reduce the volume of packages, while simultaneously increasing the price.
In other words, we want to produce smaller items and sell them at a higher price.
Note that the corresponding pre-conditioned scores are defined as $\mathcal{S}^{\mathrm{vol}}=1-\operatorname{ECDF}^{\mathrm{vol}}$ and $\mathcal{S}^{\mathrm{price}}=\operatorname{ECDF}^{\mathrm{price}}$, respectively, such that a relatively low observed volume has a high score, and a relatively high observed price has a high score.
This problem has no ground truth.
It is a classical MOOP where the decision maker may express some __preference__ for the trade-off of a desirable solution.

__Goal__: Learn hyperparameters that maximize the scalarizer given the trade-off preference.

__Formulation__: The scalarizer is perhaps simply defined as in \eqref{eq:ex1-scalarizer} and the optimization lies in finding the hyperparameters that maximize it \eqref{eq:ex1-argmax}.


\begin{align}
  \mathcal{O}(\mathbf{h})&=w_1\mathcal{S}^{\mathrm{vol}}+w_2\mathcal{S}^{\mathrm{price}}\label{eq:ex1-scalarizer}\text{ (scalarizer),}
  \\[1ex]
  \argmax{\mathbf{h}\in\mathcal{H}}\,\mathcal{O}(\mathbf{h})&\label{eq:ex1-argmax}\text{ (maximization problem)}.
\end{align}


Perturbations to the preference (weights) can lead to different Pareto optimal solutions. However, since the scalarizer's value gives an indication as to the _absolute_ goodness of the solution (since the trade-off is now perfectly quantifiable), we can select the best solution among a set of solutions that were produced with the same preference.
The conjecture is, however, that this scalarizer produces unique Pareto optimal solutions. This means that in this case, there is a unique Pareto optimal solution for every possible realization of the preference.



## Czech problem: Finding variable importance

In this problem, we have a ground truth \eqref{eq:cz-gt} and hundreds of objectives. Each objective measures the deviation from some ideal continuous process model, in a specific segment.
We pre-condition these objectives by simulating a large number of random processes as they may occur in reality. We do this to obtain losses as they typically occur given the _constant_ process model (i.e., what is a typical deviation from the process model in a given segment).
In the next step, we take the $15$ processes that were actually observed (the student projects) and compute the losses for each project and each objective. This results in a loss matrix $\mathbf{L}^{m\times n}$, where $m$ is the projects, and $n$ the objective.
Next, this loss matrix is transformed into a score matrix $\mathbf{S}^{m\times n}$ \eqref{eq:score-mat}, by plugging each project's $n$-th loss into the corresponding $\operatorname{ECCDF}$ (i.e., $1-\operatorname{ECDF}$) as approximated before (a low observed loss corresponds to a high score).

__Goal__: Find variable importances such that we can learn which loss in which segment is important in order to predict the ground truth.

__Formulation__: We use the words _variable importance_ instead of weights, as the scalarizer is a weighted mean \eqref{eq:cz-scalarizer}. In it, all coefficients must be larger than or equal to $0$, but not all of them can be $0$. Instead of a constraint, we use a piece-wise definition \eqref{eq:correct-ratios} where all weights are set to $1$ when they are all zero, as they all are equally important (we do this for numeric stability so we are not dividing by $0$).


\begin{align}
  \mathbf{S}&\dots m\times n\text{ matrix of projects' scores,}\label{eq:score-mat}
  \\[1ex]
  \mathbf{y}&\dots\text{ vector of length $m$ containing the ground truth,}\label{eq:cz-gt}
  \\[1ex]
  \mathbf{w}&\dots\text{ weight vector with $n$ weights,}\nonumber
  \\[1ex]
  \mathbf{w}'&=\begin{cases}
      \mathbf{1},&\text{if}\;\norm{\mathbf{w}}=0\;\text{(set to vector of ones),}
      \\
      \mathbf{w},&\text{otherwise,}
  \end{cases}\label{eq:correct-ratios}
  \\[1ex]
  \mathcal{O}(\mathbf{w})&=\frac{1}{m}\sum_{i=1}^{m}\,\left(y_i-\left[\sum_{j=1}^{n}\,w_j \mathbf{S}_{i,j}\norm{\mathbf{w}}_1^{-1}\right]\right)^2\text{ (scalarizer),}\label{eq:cz-scalarizer}
  \\[1ex]
  \argmin{\mathbf{w}\in\mathcal{W}}\,\mathcal{O}(\mathbf{w}')&\text{ (minimization problem),}\label{eq:cz-problem}
  \\[1ex]
  \text{subject to }&\forall\,w\in\bm{w},w\geq0\;\land\;\norm{\bm{w}}>0\nonumber,
  \\[1ex]
  &\text{within the box bounds }\interval{0}{1}\nonumber.
\end{align}


Obviously, here we want to minimize the deviation between the ground truth and the predicted ground truth \eqref{eq:cz-problem}. The variable importances can directly be used in a regression model (using the scalarizer from the objective).



# Research

Here we list a few open problems that could be subject to potential research.

* Pre-conditioned scores lead to _proper_ Pareto optimal solutions, where _properly_ refers to unbounded trade-offs between the objectives __not__ being allowed. In fact, not only are the trade-offs bounded, but further _comparable_. We need to investigate what the impact of this is.
* Specifying preference with ordinary or simply scaled objectives in a MOOP may not lead to the desired result. We would have to investigate if using pre-conditioned scores alleviates the problem. The role of weights (relative importance) has been shown to be often misleading (e.g., @roy1996theoretical). We have to investigate if this role is more clear now using pre-conditioned scores.
* Conjecture: A linear scalarizer using pre-conditioned scores produces a) provably Pareto optimal solutions, and b) unique solutions (same preference leads to the same solution).
* An evenly distributed set of weights does not necessarily produce an evenly distributed representation of the Pareto optimal set, even if the problem is convex. We would need to investigate if this still applies when using pre-conditioned scores instead of raw or scaled objectives.



# Examples

In this section, we will make some tests, that is, compute some actual problems and examine what the impact of pre-conditioning is.


## Problem 1

Here, we pick a problem for optimization from[^1].
More concretely, we will optimize the Fonseca–Fleming function [@fonseca1995].
We know about this problem that it has a $50$/$50$ trade-off optimum at $\approx[0.63212,0.63212]$. Setting all weights to zero will lead to it.
However, it is hard to achieve the actually desired trade-off in this problem. While we can compute the Pareto front on which all solutions are considered to be equally good, we can show using pre-conditioning that this is not actually true, as we now have the means to __order__ solutions.
Therefore, the solutions often jump to either $\approx[0,1]$ or $\approx[1,0]$.

The problem is defined as in \eqref{eq:dtlz1}.

\begin{align}
  \min_{\mathbf{x}\in\mathcal{X},i\in\mathbb{N}}\,&\begin{cases}
    f_1(\mathbf{x})&=1-\exp{\left[-\sum_{j=1}^{i}\,\left(x_j-\frac{1}{\sqrt{i}}\right)^2\right]},
    \\[1em]
    f_2(\mathbf{x})&=1-\exp{\left[-\sum_{j=1}^{i}\,\left(x_j+\frac{1}{\sqrt{i}}\right)^2\right]},
  \end{cases}\label{eq:dtlz1}
  \\[1ex]
  \text{subject to }&-4\leq x_i\leq4\nonumber,
  \\[0ex]
  &i\in\mathbb{N}\nonumber.
\end{align}


We will test this problem with __`10`__ variables ($i=10$).

```{r}
# Set up number of variables and lower/upper bounds for this problem:
i <- 10
lb <- -4
ub <- 4
```


The __goal__ of this problem is to apply pre-conditioning so that we are able to find solutions that match our preference better.

Here is what we will do:

1. Compute the Pareto front for the problem:
    * I suggest using a so-called augmented Chebyshev scalarizer [@miettinen2008], as it has a couple of advantages: It avoids weakly Pareto optimal solutions, it uses the utopian vector as reference point for optimization (which is just a vector of ones/highest scores in our case), it can find any Pareto optimal solution
    * We would express the preference a priori using the weights in the scalarizer, and then repeat the optimization a few times with different random starting points.
    * This way we'd get an idea of how the weights actually lead to a desired trade-off
2. Transform all problems to P* using pre-conditioning
3. Repeat what we have done in 2 with all P*. Now we can investigate the following:
    * Does the solution lie on the Pareto front? If not, how far off is it? If off, is it within margin of error or is there significance?
    * Since we have calibrated scores and a preference per solution, we can now exactly measure by how far the trade-off between objectives deviates from the trade-off as found by the solution. For example, we perhaps wanted a 50:50 trade-off, so the solution must be, e.g., $\approx\interval{0.3}{0.31}$, $\approx\interval{1}{1}$, $\approx\interval{0.75}{0.73}$, etc.; i.e., the scores must be well-balanced in this case.

In this kind of problem, the preference is expressed by the decision maker a priori or interactively, and then one would find the hyperparameters that produce a Pareto optimal solution according to this preference. However, and I think here is another edge: If the scalarizer were a weighted mean (as in the CZ problem), and we would learn the weights as well, then the optimization would perhaps find the single (global) absolute best solution, that produces the maximum possible score of the entire trade-off.
We will investigate this here as well (see section \ref{sssec:ex1-abs-best}).


[^1]: https://en.wikipedia.org/wiki/Test_functions_for_optimization


First we will use a simple weighting method, in which we express the preference a priori and then minimize the objective \eqref{eq:ex1-obj}.

\begin{align}
  \min_{\mathbf{x}\in\mathbb{R}^i}\,\mathcal{O}=w_1 f_1(\mathbf{x}) + w_2 f_2(\mathbf{x})\label{eq:ex1-obj}.
\end{align}


### Pareto front

We will compute the Pareto front using some randomly chosen weights.
First we define the first problem's single objectives in `R`:

```{r}
# For this one, values are astronomically small, so we cannot pre-condition the problem!
# Another problem is, that the objectives become non-conflicting at some point. For
# example, both have their global minimum at the zero vector. This means, we cannot use
# weights to achieve a trade-off any longer. It actually appears that both objectives
# are kind of mirroring each other.
ex1_f1 <- function(x) {
  l <- length(x)
  1 - exp(-1 * sum((x - 1 / sqrt(l))^2))
}
ex1_f2 <- function(x) {
  l <- length(x)
  1 - exp(-1 * sum((x + 1 / sqrt(l))^2))
}
```

Then the weighted objective:

```{r}
ex1_scalarizer <- function(x, w) {
  w[1] * ex1_f1(x) + w[2] * ex1_f2(x)
}
```

Let's define a wrapper for our optimization routines:

```{r}
do_opt <- function(fn, x0 = stats::runif(n = i, min = lb, max = ub), grad = function(x_) pracma::grad(f = fn, x0 = x_), lower = rep(lb, i), upper = rep(ub, i)) {
  nloptr::nloptr(
    x0 = x0,
    opts = list(
      maxeval = 1e3,
      algorithm = "NLOPT_LD_TNEWTON_RESTART"),
    eval_f = fn,
    eval_grad_f = grad,
    lb = lower,
    ub = upper)
}
```


Let's do some quick tests using various weights. We would want that our preference is to be found in the solution.
So for example, equal weights should lead to a loss of $\approx[0.63,0.63]$ for objectives $f_1,f_2$.


```{r}
set.seed(1337)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(n = 10)), ncol = 2, byrow = TRUE)

temp1 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  res <- do_opt(fn = function(x) ex1_scalarizer(x = x, w = temp[idx, ]))
  c(ex1_f1(res$solution), ex1_f2(res$solution))
}), ncol = 2, byrow = TRUE)

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 2] / temp1[idx, 1])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
```

```{r echo=FALSE}
if (interactive()) {
  temp3
} else {
  knitr::kable(
    x = temp3,
    booktabs = TRUE,
    caption = "Desired and actual trade-offs (TO) for the first example problem in its original form.",
    label = "ex1-tradeoffs-org"
  )
}
```

So it appears that we cannot actually optimize the problem in its original form, as the loss of both objectives is always $\approx1$ (table \ref{tab:ex1-tradeoffs-org}). This is perhaps due to its numerical instability, as perturbations to the weights result only in abysmal changes.
If the changes are too small, then so is the gradient. With the maximum possible loss (given random starting values), the trade-off of $1$:$1$ is always the same and the results are useless.
Therefore, we need to re-define the problem in a more numerically stable way.

We will use the following surrogate functions to map the objectives of the optimization problem into a more numerically stable range ($\log$-transform).
In pre-conditioning, we want to learn a __bijective__ function that maps a loss to a score, so this is a valid thing to do, as long as we apply the _same_ transformation to _all_ objectives.


```{r}
ex1_f1_prime <- function(x) {
  l <- length(x)
  1 - log(exp(-1 * sum((x - 1 / sqrt(l))^2)))
}
ex1_f2_prime <- function(x) {
  l <- length(x)
  1 - log(exp(-1 * sum((x + 1 / sqrt(l))^2)))
}
```

```{r}
ex1_scalarizer_prime <- function(x, w) {
  w[1] * ex1_f1_prime(x) + w[2] * ex1_f2_prime(x)
}
```


We can now attempt to re-run the previous test using these versions.

```{r}
set.seed(1337)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(n = 10)), ncol = 2, byrow = TRUE)

temp1 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  res <- do_opt(fn = function(x) ex1_scalarizer_prime(x = x, w = temp[idx, ]))
  c(ex1_f1(res$solution), ex1_f2(res$solution))
}), ncol = 2, byrow = TRUE)

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 2] / temp1[idx, 1])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
```

```{r echo=FALSE}
if (interactive()) {
  temp3
} else {
  knitr::kable(
    x = temp3,
    booktabs = TRUE,
    caption = "Desired and actual trade-offs (TO) for the first example problem, as transformed to a more numerically stable version.",
    label = "ex1-tradeoffs-prime"
  )
}
```

Now we get some more usable results. Table \ref{tab:ex1-tradeoffs-prime} shows that with a slightly transformed version of the first example problem, we can achieve trade-offs, although they are often not close to what we wanted.

The average difference in percent between trade-offs is $\approx$ `r round(100 * mean(abs(temp3[, "TO_diff_perc"])), 2)`% (with a maximum deviation of `r round(100 * max(abs(temp3[, "TO_diff_perc"])), 2)`%), which is perhaps unusable in practice.

In order to approximate the Pareto front, we will simulate a large number of possible weight constellations.
We will compute the problem for $5,000$ different weight constellations (table \ref{tab:ex1-pareto-weights}):

```{r}
set.seed(1001)
constellations <- 5e3

weight_grid <- data.frame(
  w1 = runif(n = constellations),
  w2 = runif(n = constellations))
```

```{r echo=FALSE}
if (interactive()) {
  head(weight_grid)
} else {
  knitr::kable(
    x = head(weight_grid, 10),
    booktabs = TRUE,
    caption = paste0("Some of the weight constellations used for the first example problem to approximate the Pareto front (10 out of ", nrow(weight_grid), " are shown)."),
    label = "ex1-pareto-weights"
  )
}
```



```{r}
res <- loadResultsOrCompute(file = "../results/ex1_pareto_front.rds", computeExpr = {
  res <- as.data.frame(doWithParallelCluster(numCores = 15, expr = {
    library(foreach)
    
    foreach::foreach(
      rn = rownames(weight_grid),
      .combine = rbind,
      .inorder = FALSE
    ) %dopar% {
      w <- as.numeric(weight_grid[rn,])
      set.seed(seed = as.numeric(rn))
      
      res <- nloptr::nloptr(
        x0 = runif(n = i, min = lb, max = ub),
        opts = list(
          maxeval = 2e2,
          algorithm = "NLOPT_LD_TNEWTON_RESTART"),
        eval_f = function(x) ex1_scalarizer_prime(x = x, w = w),
        eval_grad_f = function(x) pracma::grad(f = function(x_) ex1_scalarizer_prime(x = x_, w = w), x0 = x),
        lb = rep(lb, i),
        ub = rep(ub, i))
      
      `colnames<-`(
        x = matrix(data = c(ex1_f1(res$solution), ex1_f2(res$solution), w, res$objective, res$solution), nrow = 1),
        value = c("f1", "f2", "w1", "w2", "value", paste0("par", 1:i)))
    }
  }))
  
  # Next, we have to identify the Pareto front, by selecting non-dominated solutions.
  res$optimal <- FALSE
  for (rn in rownames(res)) {
    this_sol <- res[rn, c("f1", "f2")]
    others <- res[rn != rownames(res), c("f1", "f2")]
    res[rn, ]$optimal <- !any(others$f1 < this_sol$f1 & others$f2 < this_sol$f2)
  }
  res
})
```


Now we show the Pareto front in figure \ref{fig:ex1-pareto-front}. The optimization found a total of __`r sum(res$optimal)`__ Pareto optimal solutions, out of __`r nrow(res)`__ potential solutions.

```{r ex1-pareto-front, echo=FALSE, fig.cap="The Pareto optimal solutions for the first example problem."}
plot(x = res$f1, y = res$f2,
     xlab = latex2exp::TeX("$f_1(x)$"), ylab = latex2exp::TeX("$f_2(x)$"),
     main = "Pareto front as found using a numerically stable version.",
     sub = "The Pareto front is shown in white.",
     pch = sapply(X = res$optimal, FUN = function(o) if (o) 25 else 1),
     cex = sapply(X = res$optimal, FUN = function(o) if (o) 1 else .4),
     col = sapply(X = res$optimal, FUN = function(o) if (o) "blue" else "#444444"))
grid()

temp <- res[res$optimal, ]
ex1_pareto_front <- temp[order(temp$f1), ]

for (j in 1:(nrow(ex1_pareto_front) - 1)) {
  lines(x = ex1_pareto_front[j:(j + 1), ]$f1, y = ex1_pareto_front[j:(j + 1), ]$f2, col = "white", lwd = 1.5)
}

legend(x = 0, y = .25, pch = c(25, 1), col = c("blue", "#444444"), legend = c("Pareto optimal solution", "dominated solution"))
```

### Pre-conditioning the problem

The goal is to approximate marginal distribution for each objective. Each objective expresses a loss, so we will be using the $\operatorname{ECCDF}$ later to transform it into a score (i.e., low loss equals high score).
For this, we will uniformly sample from the hyperparameter space.
For this problem, we have $i$ parameters.
The samples' matrix will therefore have dimensions $m\times i$, where $m$ is the number of samples we wish to draw. This number should be $\ll\norm{\mathcal{H}}$, i.e., much fewer samples than the hyperparameter space's size.
Here, we will draw $1,000$ samples.

For this, we will create another (but smaller) random grid that will be used to sample from the solution space of $f_1,f_2$.

```{r}
set.seed(2002)
constellations <- 1e3

prec_weight_grid <- matrix(data = runif(n = constellations * i, min = lb, max = ub), ncol = i)
```




No we can come up with the empirical marginal distributions.

```{r}
# Objective no. 1:
ex1_f1_ecdf_vals <- sapply(X = 1:nrow(prec_weight_grid), FUN = function(idx) {
  ex1_f1_prime(x = as.numeric(prec_weight_grid[idx, ]))
})
ex1_f1_ecdf <- stats::ecdf(ex1_f1_ecdf_vals)
ex1_f1_eccdf <- function(x) 1 - ex1_f1_ecdf(x)


# .. and no. 2:
ex1_f2_ecdf_vals <- sapply(X = 1:nrow(prec_weight_grid), FUN = function(idx) {
  ex1_f2_prime(x = as.numeric(prec_weight_grid[idx, ]))
})
ex1_f2_ecdf <- stats::ecdf(ex1_f2_ecdf_vals)
ex1_f2_eccdf <- function(x) 1 - ex1_f2_ecdf(x)
```


The $\operatorname{ECCDF}$s of the two objectives in figure \ref{fig:ex1-eccdfs} are clearly non-linear, indicating that not every loss is equally likely.
Since we drew only few samples, the $\operatorname{ECCDF}$s are not perfectly smooth.

```{r ex1-eccdfs, fig.cap="The empirical complementary cumulative distribution functions for losses as sampled from either objective from example 1."}
par(mfrow = c(1, 2))

curve2(func = ex1_f1_eccdf, from = min(ex1_f1_ecdf_vals), to = max(ex1_f1_ecdf_vals), main = "ECCDF of f1", ylab = "f1(x)")
curve2(func = ex1_f2_eccdf, from = min(ex1_f2_ecdf_vals), to = max(ex1_f2_ecdf_vals), main = "ECCDF of f2", ylab = "f2(x)")
```

### Testing the pre-conditioned problem

Now that we have a working transformation from objective values (losses) to corresponding linear scores, we can test how well optimization works with these.
In order to map a hyperparameter vector to a score, we need to pass it to the surrogate function, of which we will pass the result into the corresponding $\operatorname{ECCDF}$.


```{r}
ex1_scalarizer_ecdf <- function(x, w = c(1, 1)) {
  s1 <- ex1_f1_eccdf(ex1_f1_prime(x))
  s2 <- ex1_f2_eccdf(ex1_f2_prime(x))
  -1 * (w[1] * s1 + w[2] * s2) # minimization
}

set.seed(1)
res <- do_opt(fn = function(x) {
  ex1_scalarizer_ecdf(x = x)
})
res
c(ex1_f1(res$solution), ex1_f2(res$solution))
```

We notice a problem here. When running this repeatedly (even with different seeds), the optimizer stops after a single iteration.
Also, the losses are quite large. This indicates that the problem cannot converge at all.
Let's check the gradients:

```{r}
pracma::grad(f = function(x) {
  ex1_scalarizer_ecdf(x = x)
}, x0 = runif(n = i, min = lb, max = ub))
```

Here is a problem. The gradient is always zero for all variables.
Let's attempt the following: Instead of estimating the ECDF, we will fit a parametric distribution. In fact, let's test the normal distribution, since the ECDFs looked quite like the CDFs of a normal distribution.
In practice, one would perhaps be better off attempting to fit a wider range of potential distributions, then going with the best (using, e.g., the $D$-statistic of the KS-test).

```{r}
ex1_f1_eccdf_norm <- (function() {
  m <- mean(ex1_f1_ecdf_vals)
  s <- sd(ex1_f1_ecdf_vals)
  function(x) {
    1 - pnorm(q = x, mean = m, sd = s)
  }
})()
ex1_f2_eccdf_norm <- (function() {
  m <- mean(ex1_f2_ecdf_vals)
  s <- sd(ex1_f2_ecdf_vals)
  function(x) {
    1 - pnorm(q = x, mean = m, sd = s)
  }
})()
```


The $\operatorname{CCDF}$s of figure \ref{fig:ex1-eccdfs-norm} look quite similar to the $\operatorname{ECCDF}$s we got empirically.
They do have a two advantages, though. First, smoothness -- we should not end up with all zeros for the gradients.
Second, an $\operatorname{ECDF}$ returns $0$ for values less than any of the observed ones, and $1$ for values beyond the observed range.
The parametric $\operatorname{CDF}$ however will never really reach $0$ or $1$, which means that even tiny differences in $x$ will result in tiny differences in $y$, before and beyond the actually observed values.

```{r ex1-eccdfs-norm, fig.cap="Fitted parametric CCDFs for samples as taken from the two objectives of example 1."}
par(mfrow = c(1, 2))

curve2(func = ex1_f1_eccdf_norm,
       from = min(ex1_f1_ecdf_vals) - 10,
       to = max(ex1_f1_ecdf_vals) + 10,
       main = "ECCDF (normal) of f1", ylab = "f1(x)")

curve2(func = ex1_f2_eccdf_norm,
       from = min(ex1_f2_ecdf_vals) - 10,
       to = max(ex1_f2_ecdf_vals) + 10, main = "ECCDF (normal) of f2", ylab = "f2(x)")
```

So let's test the gradient again:

```{r}
ex1_scalarizer_ecdf_norm <- function(x, w = c(1, 1)) {
  s1 <- ex1_f1_eccdf_norm(ex1_f1_prime(x))
  s2 <- ex1_f2_eccdf_norm(ex1_f2_prime(x))
  -1 * (w[1] * s1 + w[2] * s2) # minimization
}

pracma::grad(f = function(x) {
  ex1_scalarizer_ecdf_norm(x = x)
}, x0 = runif(n = i, min = lb, max = ub))
```


Much better! Now we are perhaps able to make the gradient-based optimization work well.

```{r}
res <- do_opt(fn = function(x) {
  ex1_scalarizer_ecdf_norm(x = x, w = c(1, 1))
})

print(res)
print(c(ex1_f1(res$solution), ex1_f2(res$solution)))
print(c(ex1_f2_eccdf_norm(ex1_f1_prime(res$solution)), ex1_f2_eccdf_norm(ex1_f2_prime(res$solution))))
```

This is an excellent result, as we are quite close to the desired $50$/$50$ trade-off for the first time.
With equal weights (actually, both $=1$), the theoretical optimal value of the scalarizer is $2$, as we are dealing now with linear scores that have a range of $\interval{0}{1}$.
The result shows that we are quite close to it.

As before, we should run a few tests to see if we are able now to get acceptable trade-offs.

```{r}
set.seed(1337)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(10)), ncol = 2, byrow = TRUE)

temp1 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  res <- do_opt(fn = function(x) ex1_scalarizer_ecdf_norm(x = x, w = temp[idx, ]))
  c(res$objective / sum(temp[idx, ]), ex1_f1(res$solution), ex1_f2(res$solution))
}), ncol = 3, byrow = TRUE)

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 3] / temp1[idx, 2])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "res", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
temp3 <- temp3[order(temp3[, "res"]),]
```

```{r echo=FALSE}
if (interactive()) {
  temp3
} else {
  knitr::kable(
    x = temp3,
    booktabs = TRUE,
    caption = "Desired and actual trade-offs for the pre-conditioned version of the first example problem.",
    label = "ex1-tradeoffs-prec"
  )
}
```


These results are good (table \ref{tab:ex1-tradeoffs-prec}). They indicate that, by an average deviation of only $\approx$ __`r round(100 * mean(temp3[, "TO_diff_perc"]), 2)`%__ (with a maximum deviation of `r round(100 * max(temp3[, "TO_diff_perc"]), 2)`%) from the desired ratio, we can get very close to the desired trade-off.
The results are ordered best to worst solution, which is another feature of pre-conditioning (orderable results). It appears that the most extreme trade-offs are the best solutions.
This confirms the conjecture we had when introducing this problem, that the solution process most likely jumps to one of the extremes (i.e., losses of $[0,1]$ or $[1,0]$).

Those results would have perhaps be even better if we had sampled more values from either loss, combined with some best-fitting parametric probability distribution (instead of just assuming the normal distribution).


### Convergence towards desired trade-off

We want to inspect how exactly the solutions converge from some random starting point using some preference.
For that, we need to track the history of the process.

```{r}
do_opt_hist <- function(fn, x0 = stats::runif(n = i, min = lb, max = ub), grad = function(x_) pracma::grad(f = fn, x0 = x_)) {
  vals <- matrix(ncol = 3 + length(x0), nrow = 0)
  colnames(vals) <- c("loss", "f1", "f2", paste0("par", 1:i))
  
  res <- stats::optim(
    par = x0,
    fn = function(x) {
      r <- fn(x)
      vals <<- rbind(vals, c(r, ex1_f1(x), ex1_f2(x), x))
      r
    },
    gr = grad,
    method = "L-BFGS-B",
    lower = rep(lb, i),
    upper = rep(ub, i)
  )
  res$history <- vals
  res
}
```


```{r}
set.seed(1338)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1), ncol = 2, byrow = TRUE)

templ <- list()
for (idx in 1:nrow(temp)) {
  templ[[idx]] <- do_opt_hist(fn = function(x) {
    ex1_scalarizer_ecdf_norm(x = x, w = temp[idx, ])
  })
}
```


Figure \ref{fig:ex1-working-tradeoffs} demonstrates how pre-conditioning allows us to converge to a desired trade-off between objectives.


```{r ex1-working-tradeoffs, echo=FALSE, fig.cap="Well-working trade-offs using a pre-conditioned version of the first example problem."}
plot(x = c(), y = c(),
     xlab = latex2exp::TeX("$f_1(x)$"), ylab = latex2exp::TeX("$f_2(x)$"),
     main = "Convergence towards Pareto front using desired trade-off.",
     xlim = c(0, max(unlist(lapply(X = templ, function(res) max(res$history[, "f1"]))))),
     ylim = c(0, max(unlist(lapply(X = templ, function(res) max(res$history[, "f2"]))))))
grid()


for (j in 1:(nrow(ex1_pareto_front) - 1)) {
  lines(x = ex1_pareto_front[j:(j + 1), ]$f1, y = ex1_pareto_front[j:(j + 1), ]$f2)
}

for (idx in 1:nrow(temp)) {
  temp1 <- templ[[idx]]
  h <- temp1$history
  for (j in 1:(nrow(h) - 1)) {
    lines(x = h[j:(j+1), "f1"], y = h[j:(j+1), "f2"])
  }
  
  last <- tail(h, 1)
  points(x = last[, "f1"], y = last[, "f2"], pch = 25, col = "blue")
  
  text(x = last[, "f1"] - .05, y = last[, "f2"] - .02, labels = paste0(temp[idx,], collapse = ":"))
  actual <- last[, c("f2", "f1")]
  actual <- actual / max(actual) * max(temp[idx, ])
  text(x = last[, "f1"] - .05, y = last[, "f2"] - .08, labels = paste0(round(actual, 2), collapse = ":"), col = "darkred")
}

legend(x = 0, y = .25, legend = c("Desired trade-off", "Actual trade-off"), col = c("black", "darkred"), lty = 1)
```

It is worth noting that we actually did not reach the $50$/$50$ trade-off of the numerical transformed problem, but we were close to it.
This is very likely due to the fitted $\operatorname{CDF}$, for which we only observed few values and which is perhaps not using the most ideal distribution.



### Bonus: Estimate nadir vector

It appears the pre-conditioned problem of the first example works well. Optimization literature tells us that objectives better be on the same scale, by dividing it by the extend of utopian- and nadir-vectors.
We will obtain these, and then attempt to obtain desired trade-offs, which did not work well so far, even with the more numerically stable surrogate objectives (it did not work at all with the original problem).

We do know that the utopian vector is $\{0,0\}^\top$, i.e., a loss of $0$ for either objective. In order to obtain the nadir vector, we can _maximize_ each objective separately.
For normalization, we simply divide by each objective's nadir value.

```{r}
ex1_nadir <- -1 * c(
  do_opt(fn = function(x) -1 * ex1_f1_prime(x = x))$objective,
  do_opt(fn = function(x) -1 * ex1_f2_prime(x = x))$objective)

ex1_nadir
```

```{r}
set.seed(1339)

ex1_scalarizer_prime_nadir <- function(x, w) {
  w[1] * ex1_f1_prime(x) / ex1_nadir[1] + w[2] * ex1_f2_prime(x) / ex1_nadir[2]
}

temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(n = 10)), ncol = 2, byrow = TRUE)

temp1 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  res <- do_opt(fn = function(x) ex1_scalarizer_prime_nadir(x = x, w = temp[idx, ]))
  c(ex1_f1(res$solution), ex1_f2(res$solution))
}), ncol = 2, byrow = TRUE)

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 2] / temp1[idx, 1])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
```

```{r echo=FALSE}
if (interactive()) {
  temp3
} else {
  knitr::kable(
    x = temp3,
    booktabs = TRUE,
    caption = "Desired and actual trade-offs (TO) for the first example problem, as transformed to a more numerically stable version and using normalized objectives as of the nadir-vector.",
    label = "ex1-tradeoffs-prime-nadir"
  )
}
```

The results are shown in table \ref{tab:ex1-tradeoffs-prime-nadir}.
The mean deviation is slightly better with $\approx$ __`r round(100 * mean(temp3[, "TO_diff_perc"]), 2)`%__, while the maximum deviation of `r round(100 * max(temp3[, "TO_diff_perc"]), 2)`% is worse.
What we clearly observe here, however, is that the more extreme the desired trade-off, the bigger the difference between it and the actual trade-off.
This did not exactly hold for the pre-conditioned problem, either.




```{r}
set.seed(1338)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1), ncol = 2, byrow = TRUE)

templ <- list()
for (idx in 1:nrow(temp)) {
  templ[[idx]] <- do_opt_hist(fn = function(x) {
    ex1_scalarizer_prime_nadir(x = x, w = temp[idx, ])
  })
}
```


Figure \ref{fig:ex1-nadir-tradeoffs} shows the trade-offs as reachable by the normalized objectives, using the numerically stabilized version of the problem.
While it might does not look so bad, recall that on average, each trade-off is off by $\approx$ `r round(100 * mean(temp3[, "TO_diff_perc"]), 2)`%.
It also appears that each optimization went straight to the solution. In the pre-conditioned version (figure \ref{fig:ex1-working-tradeoffs}), convergence was not straight, and one could clearly observe that the direction adapted and improved towards the solution with the desired trade-off.


```{r ex1-nadir-tradeoffs, echo=FALSE, fig.cap="Pareto trade-offs using the numerically stabilized version of the first problem, together with normalized objectives."}
plot(x = c(), y = c(),
     xlab = latex2exp::TeX("$f_1(x)$"), ylab = latex2exp::TeX("$f_2(x)$"),
     main = "Convergence towards Pareto front using normalized objectives.",
     xlim = c(0, max(unlist(lapply(X = templ, function(res) max(res$history[, "f1"]))))),
     ylim = c(0, max(unlist(lapply(X = templ, function(res) max(res$history[, "f2"]))))))
grid()


for (j in 1:(nrow(ex1_pareto_front) - 1)) {
  lines(x = ex1_pareto_front[j:(j + 1), ]$f1, y = ex1_pareto_front[j:(j + 1), ]$f2)
}

for (idx in 1:nrow(temp)) {
  temp1 <- templ[[idx]]
  h <- temp1$history
  for (j in 1:(nrow(h) - 1)) {
    lines(x = h[j:(j+1), "f1"], y = h[j:(j+1), "f2"])
  }
  
  last <- tail(h, 1)
  points(x = last[, "f1"], y = last[, "f2"], pch = 25, col = "blue")
  
  text(x = last[, "f1"] - .05, y = last[, "f2"] - .02, labels = paste0(temp[idx,], collapse = ":"))
  actual <- last[, c("f2", "f1")]
  actual <- actual / max(actual) * max(temp[idx, ])
  text(x = last[, "f1"] - .05, y = last[, "f2"] - .08, labels = paste0(round(actual, 2), collapse = ":"), col = "darkred")
}

legend(x = 0, y = .25, legend = c("Desired trade-off", "Actual trade-off"), col = c("black", "darkred"), lty = 1)
```



### Absolute best solution\label{sssec:ex1-abs-best}

There is one thing left to do. Not only do we want to find the hyperparameters that maximize the scores, but we will now simultaneously attempt to learn the weights using a weighted mean.

```{r}
set.seed(7)
do_opt(fn = function(x) {
  w <- tail(x, 2)
  x <- head(x, i)
  -1 * (w[1] * ex1_f1_eccdf_norm(ex1_f1_prime(x)) + w[2] * ex1_f2_eccdf_norm(ex1_f2_prime(x))) / sum(w)
}, x0 = c(runif(n = i, min = lb, max = ub), runif(2)),
    lower = c(rep(lb, i), .Machine$double.eps, .Machine$double.eps), # do not allow 0
    upper = c(rep(ub, i), 1, 1)) # + weights
```

Now we can say with certainty that there are two equally absolute best solutions for this problem, where one favors the first objective (the second having no weight) and one favors the second objective.
Using the seed of $1$ leads to weights $[1,0]$, and using a seed of $7$ leads to weights $[0,1]$. No matter the seed, one weight is always (practically) $0$, while the other is $>0$. In a weighted mean, it does not matter by how much the one weight is greater than zero, just that it is (as normalization of a zero-weight will not make it larger).



### Using some best-fitting distribution

Here we will try to fit the best possible 


```{r warning=FALSE}
library(ExtDist)

# First objective:
temp <- bestDist(X = ex1_f1_ecdf_vals, criterion = "BIC", candDist = c("Beta_ab", "Beta", "Normal", "Laplace", "JohnsonSU", "Gamma", "Exp", "Gumbel", "Logistic", "Weibull", "SRTB_ab", "Triangular"))
ex1_f1_best_dist_par <- as.list(unlist(attributes(temp)$best.dist.par))
ex1_f1_best_dist <- get(paste0("p", temp[1]))
ex1_f1_eccdf_best <- function(x) {
  ex1_f1_best_dist_par$params <- ex1_f1_best_dist_par
  ex1_f1_best_dist_par$q <- x
  1 - do.call(what = ex1_f1_best_dist, args = ex1_f1_best_dist_par)
}
temp[1]
```

```{r warning=FALSE}
# Second objective:
temp <- bestDist(X = ex1_f2_ecdf_vals, criterion = "BIC", candDist = c("Normal", "Laplace", "JohnsonSU", "Gamma", "Exp", "Gumbel", "Logistic", "Weibull", "SRTB_ab", "Triangular"))
ex1_f2_best_dist_par <- as.list(unlist(attributes(temp)$best.dist.par))
ex1_f2_best_dist <- get(paste0("p", temp[1]))
ex1_f2_eccdf_best <- function(x) {
  ex1_f2_best_dist_par$params <- ex1_f2_best_dist_par
  ex1_f2_best_dist_par$q <- x
  1 - do.call(what = ex1_f2_best_dist, args = ex1_f2_best_dist_par)
}
temp[1]
```

Let's compare:

```{r}
par(mfrow = c(1, 2))

curve2(ex1_f1_eccdf_norm, min(ex1_f1_ecdf_vals) - 10, max(ex1_f1_ecdf_vals) + 10, ylab = latex2exp::TeX("${CCDF}_{f_1}(x)$"))
grid()
curve2(ex1_f1_eccdf_best, min(ex1_f1_ecdf_vals) - 10, max(ex1_f1_ecdf_vals) + 10, col = "red", add = TRUE)
legend(x = -5, y = 0.15, lty = 1, col = c("black", "red"), legend = c("Normal CDF", "Beta_ab CDF"), cex = .8)

curve2(ex1_f2_eccdf_norm, min(ex1_f2_ecdf_vals) - 10, max(ex1_f2_ecdf_vals) + 10, ylab = latex2exp::TeX("${CCDF}_{f_2}(x)$"))
grid()
curve2(ex1_f2_eccdf_best, min(ex1_f2_ecdf_vals) - 10, max(ex1_f2_ecdf_vals) + 10, col = "red", add = TRUE)
```

By visual inspection we can see that for the first objective, there is a slight difference. Let's zoom in at some points (fig \ref{fig:}).

```{r bla, echo=FALSE, fig.height=7}
par(mfrow = c(2, 2))


curve2(ex1_f1_eccdf_norm, 0, 20, ylab = latex2exp::TeX("${CCDF}_{f_1}(x)$"))
grid()
curve2(ex1_f1_eccdf_best, 0, 20, col = "red", add = TRUE)

curve2(ex1_f1_eccdf_norm, 10, 40, ylab = latex2exp::TeX("${CCDF}_{f_1}(x)$"))
grid()
curve2(ex1_f1_eccdf_best, 10, 40, col = "red", add = TRUE)

curve2(ex1_f1_eccdf_norm, 55, 70, ylab = latex2exp::TeX("${CCDF}_{f_1}(x)$"))
grid()
curve2(ex1_f1_eccdf_best, 55, 70, col = "red", add = TRUE)

curve2(ex1_f1_eccdf_norm, 75, 115, ylab = latex2exp::TeX("${CCDF}_{f_1}(x)$"))
grid()
curve2(ex1_f1_eccdf_best, 75, 115, col = "red", add = TRUE)

```


```{r}
ks.test(ex1_f1_ecdf_vals, ex1_f1_eccdf_norm)$statistic < ks.test(ex1_f1_ecdf_vals, ex1_f1_eccdf_best)$statistic
```


Apparently, only the first objective has a somewhat different distribution (two-parameter Beta distribution), while the maximum likelihood for the second objective is a normal distribution as well (the exact same).

```{r}
ex1_scalarizer_ecdf_best <- function(x, w = c(1, 1)) {
  s1 <- ex1_f1_eccdf_best(ex1_f1_prime(x))
  s2 <- ex1_f2_eccdf_best(ex1_f2_prime(x))
  -1 * (w[1] * s1 + w[2] * s2) # minimization
}

pracma::grad(f = function(x) {
  ex1_scalarizer_ecdf_best(x = x)
}, x0 = runif(n = i, min = lb, max = ub))
```


```{r}
set.seed(1337)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(10)), ncol = 2, byrow = TRUE)

temp1 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  res <- do_opt(fn = function(x) ex1_scalarizer_ecdf_best(x = x, w = temp[idx, ]))
  c(res$objective / sum(temp[idx, ]), ex1_f1(res$solution), ex1_f2(res$solution))
}), ncol = 3, byrow = TRUE)

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 3] / temp1[idx, 2])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "res", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
temp3 <- temp3[order(-temp3[, "TO_wanted"]),]
temp3
```


### EPDF to ECDF

```{r}
temp <- stats::density(x = ex1_f1_ecdf_vals, n = 2^15)
x_first <- min(temp$x) - (max(temp$x) - min(temp$x)) / 2
x_last <- max(temp$x) + (max(temp$x) - min(temp$x)) / 2

tempf <-stats::approxfun(
  x = c(x_first, temp$x, x_last),
  y = c(0, temp$y, 0),
  yleft = 0, yright = 0)

curve2(func = tempf, from = -1, to = 10)
tempf <- function(x) dnorm(x = x, mean = mean(ex1_f1_ecdf_vals), sd = sd(ex1_f1_ecdf_vals))
curve2(tempf, x_first, x_last, col="red", add=TRUE)
```



```{r}
ex1_f1_eccdf_epdf <- (function() {
  temp <- stats::density(x = ex1_f1_ecdf_vals, n = 2^15)
  x_first <- min(temp$x) - (max(temp$x) - min(temp$x)) / 2
  x_last <- max(temp$x) + (max(temp$x) - min(temp$x)) / 2

  tempf <-stats::approxfun(
    x = c(x_first, temp$x, x_last),
    y = c(0, temp$y, 0),
    yleft = 0, yright = 0)
  
  Vectorize(function(x) {
    1 - cubature::cubintegrate(f = tempf, lower = x_first, upper = x)$integral
  })
})()
```

```{r}
curve2(func = ex1_f1_eccdf_epdf, from = x_first, to = x_last)
curve2(func = ex1_f1_eccdf_norm, from = x_first, to = x_last, col="red", add=TRUE)
```

```{r}
ex1_f2_eccdf_epdf <- (function() {
  temp <- stats::density(x = ex1_f2_ecdf_vals, n = 2^15)
  x_first <- min(temp$x) - (max(temp$x) - min(temp$x)) / 2
  x_last <- max(temp$x) + (max(temp$x) - min(temp$x)) / 2

  tempf <-stats::approxfun(
    x = c(x_first, temp$x, x_last),
    y = c(0, temp$y, 0),
    yleft = 0, yright = 0)
  
  Vectorize(function(x) {
    1 - cubature::cubintegrate(f = tempf, lower = x_first, upper = x)$integral
  })
})()
```

```{r}
curve2(func = ex1_f2_eccdf_epdf, from = x_first, to = x_last)
curve2(func = ex1_f2_eccdf_norm, from = x_first, to = x_last, col="red", add=TRUE)
```





```{r}
ex1_scalarizer_ecdf_epdf <- function(x, w = c(1, 1)) {
  s1 <- ex1_f1_eccdf_epdf(ex1_f1_prime(x))
  s2 <- ex1_f2_eccdf_epdf(ex1_f2_prime(x))
  -1 * (w[1] * s1 + w[2] * s2) # minimization
}

pracma::grad(f = function(x) {
  ex1_scalarizer_ecdf_epdf(x = x)
}, x0 = runif(n = i, min = lb, max = ub))
```


```{r}
set.seed(1337)
temp <- matrix(data = c(1,1, 1,2, 1,3, 1,5, 1,10, 2,1, 3,1, 5,1, 10,1, runif(10)), ncol = 2, byrow = TRUE)

temp1 <- loadResultsOrCompute(file = "../results/ex1_eccdf_epdf.rds", computeExpr = {
  matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
    res <- do_opt(fn = function(x) ex1_scalarizer_ecdf_epdf(x = x, w = temp[idx, ]))
    c(res$objective / sum(temp[idx, ]), ex1_f1(res$solution), ex1_f2(res$solution))
  }), ncol = 3, byrow = TRUE)
})

temp2 <- matrix(data = sapply(X = 1:nrow(temp), FUN = function(idx) {
  # Return wanted vs. gotten trade-off
  foo <- c(temp[idx, 1] / temp[idx, 2], temp1[idx, 3] / temp1[idx, 2])
  c(foo, abs(foo[1] - foo[2]) / (temp[idx, 1] / temp[idx, 2]))
}), ncol = 3, byrow = TRUE)

temp3 <- `colnames<-`(
  x = cbind(round(temp, 3), round(temp1, 5), round(temp2, 5)),
  value = c("w1", "w2", "res", "loss_f1", "loss_f2", "TO_wanted", "TO_gotten", "TO_diff_perc"))
temp3 <- temp3[order(-temp3[, "TO_wanted"]),]
temp3
```

```{r}
mean(abs(temp3[, "TO_diff_perc"]))
max(abs(temp3[, "TO_diff_perc"]))
```




## Problem 3

We will formulate a problem similar to a problem that we have in the Czech project.
There, we have an expectation formulated as a curve, but we know it is not ideal w.r.t. the actual observations we make. We want to adjust this curve such that it better matches the observations.
If we think of the expectation as our _process model_ (PM), then we want to adjust this PM to better accommodate the observed _processes_.
Here, we'll be using only one observation. In reality, we'd probably have a set of (weighted) observations.


The degrees of freedom of this problem are: vertical translation, scaling, and a slope.
We are attempting to optimize these objectives:

* a
* b

We want to find an adjustment that is a _compromise_ of the following objectives.


```{r ex3-pm-and-p}
par(mfrow = c(2,1))

ex3_pm <- function(x, w) {
  # slope
  a <- w[1]
  # offset
  b <- w[2]
  
  s_x <- w[3]
  s_y <- w[4]
  
  #min(1, max(0, b + a*x + s_y * sin(x = s_x * x / pi)))
  b + a*x + s_y * sin(x = s_x * x * pi)
}
```

```{r}
temp <- c(0, 0, 1.5, 1.5)
curve2(func = Vectorize(function(x) {
  ex3_pm(x, temp)
}), 0, 1, ylim = c(0, 1))
```






# References {-}

<div id="refs"></div>










